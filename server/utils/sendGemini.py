import google.generativeai as genai
import json
import os
from typing import Dict, Any
from dotenv import load_dotenv

# Load environment variables from a .env file
load_dotenv()

def parse_with_gemini(system_prompt: str, raw_keywords: Dict[str, Any], temperature: float = 0.1) -> Dict[str, Any]:
    """
    Parses raw keywords from a job description using the Gemini API.

    Args:
        system_prompt: The detailed instructions for the AI on how to parse the data.
        raw_keywords: A dictionary containing the messy keywords extracted from the JD.
        temperature: The creativity level for the model's response (lower is more deterministic).

    Returns:
        A structured dictionary with the parsed job description data.
    """
    
    # Get the API key from environment variables
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        raise ValueError("GEMINI_API_KEY not found. Please set it in your .env file.")
    
    # Configure the Gemini client
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.0-flash')
    
    # --- THIS IS THE CORRECTED PART ---
    # Convert the raw_keywords dictionary to a JSON string to include in the prompt
    keywords_json_string = json.dumps(raw_keywords, indent=2)
    
    # Combine the instructions (system_prompt) with the actual data to be processed.
    # A clear separator helps the model understand its task.
    full_prompt = f"""{system_prompt}

# INPUT DATA TO PARSE
Now, process the following raw JSON data based on the rules you were given:

{keywords_json_string}
"""
    
    # Generate the response from the model
    response = model.generate_content(
        full_prompt,
        generation_config=genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=4096,  # Adjust if needed for very long JDs
        )
    )
    
    # Extract and clean the response text
    response_text = response.text.strip()
    
    # Remove markdown code block formatting (e.g., ```json ... ```) if present
    if response_text.startswith('```'):
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}')
        if start_idx != -1 and end_idx != -1:
            response_text = response_text[start_idx:end_idx + 1]
    
    # Parse the cleaned text into a Python dictionary and return it
    try:
        return json.loads(response_text)
    except json.JSONDecodeError as e:
        print(f"Error decoding JSON from model response: {e}")
        print(f"Raw response from model:\n{response_text}")
        return {"error": "Failed to parse model response as JSON."}


# This block runs when the script is executed directly
if __name__ == "__main__":
    
    # This is the detailed set of instructions for the AI
    system_prompt = """
# System Prompt: Advanced Job Description Parser for Software Engineering Roles

You are an expert technical data analyst specializing in parsing software engineering job descriptions. Your task is to analyze a messy JSON object containing keywords extracted from a job description and transform it into a clean, structured, granular JSON object optimized for ATS and job matching systems.

## CONTEXT
The input JSON was generated by a script and contains noisy keywords and experience requirements. It needs to be cleaned, filtered, and structured with maximum granularity for precise skill matching.

## CORE PRINCIPLES
1. **Granularity Over Grouping**: Break down composite skills into atomic units.
2. **Specificity**: Distinguish between similar technologies (e.g., React vs React Native).
3. **Context Awareness**: Categorize based on actual usage context (e.g., Jenkins is CI/CD).
4. **Relevance**: Only include skills that demonstrate technical capability or job requirements.

## CLEANING RULES
- Remove all newline characters (\\n), extra whitespace, and special characters.
- Standardize capitalization (e.g., "javascript" → "JavaScript", "aws" → "AWS").
- Expand abbreviations where clear (e.g., "k8s" → "Kubernetes").
- Correct obvious typos and remove duplicate entries.

## CATEGORIZATION SCHEMA
Your output MUST conform to this JSON structure. Use empty arrays `[]` or objects `{}` for categories with no matches. DO NOT omit any keys.

- **job_title**: string
- **experience_years**: object (`{"min": integer, "max": integer or null}`)
- **programming_languages**: array of strings
- **frontend_frameworks**: array of strings
- **backend_frameworks**: array of strings
- **databases**: object (`{"relational": [], "nosql": [], "in_memory": [], "search_engines": [], "graph": [], "time_series": []}`)
- **cloud_platforms**: object (`{"providers": [], "aws_services": [], "azure_services": [], "gcp_services": []}`)
- **devops_and_infrastructure**: object (`{"containerization": [], "orchestration": [], "ci_cd": [], "iac": [], "monitoring": [], "version_control": []}`)
- **messaging_and_streaming**: array of strings
- **testing_frameworks**: object (`{"unit_testing": [], "integration_testing": [], "e2e_testing": [], "performance_testing": []}`)
- **build_and_package_managers**: array of strings
- **apis_and_protocols**: array of strings
- **markup_and_styling**: array of strings
- **architectural_patterns**: array of strings
- **methodologies**: array of strings
- **security**: array of strings
- **operating_systems**: array of strings
- **data_processing**: array of strings
- **machine_learning**: array of strings
- **mobile_development**: array of strings
- **soft_skills**: array of strings
- **certifications**: array of strings
- **other_technical_skills**: array of strings

## AGGRESSIVE FILTERING
**Discard these types of keywords:** "role", "position", "duties", "responsibilities", "summary", "experience with", "knowledge of", "team player", etc.

## OUTPUT FORMAT
Return ONLY a single valid JSON object with no additional text, markdown formatting, or explanations.

"""
    
    # This is the messy data extracted from a Job Description
    raw_keywords = {
        "keywords": [
            "(gmt+05:30) asia/kolkata", "2.00 + years\n\nsalary", "30 days\n\nshift", "a cloud platform", 
            "a culture", "a focus", "a highly skilled and motivated backend developer", "a professional capacity", 
            "a requirement", "actions", "an understanding", "api", "api development", "apis", "applications", 
            "architect", "asia", "at least one python framework", "aws", "azure", "backend", "backend developer", 
            "best practices", "both python", "building", "caching strategies", "ci/cd pipelines", 
            "ci/cd: practical experience building", "cloud", "cloud computing platforms", 
            "cloud-native development practices", "code reviews", "collaboration skills", "communication", 
            "complex and efficient sql", "containerization technologies", "continuous improvement", "data integrity", 
            "databases", "debug", "deployment processes", "design", "developer", "development", "django", "docker", 
            "expertise", "familiarity", "fastapi", "flask", "frameworks", "front-end developers", 
            "full time indefinite contract(40", "gcp", "gcp\n\nmoii ai", "github", "github actions", "gmt+05:30", 
            "golang", "good", "google", "google cloud platform", "hands-on experience", "high-performance applications", 
            "indefinite", "inr", "ist", "key responsibilities\n\n  design", "knowledge", "kolkata", "kubernetes", 
            "languages", "management", "microservices architecture", "moii", "new features", "notice", "notice period", 
            "opportunity", "opportunity type", "other major providers", "other stakeholders", "our applications", 
            "our engineering team", "performance", "performance optimization", "period", "placement", "platform", 
            "preferred", "preferred qualifications\n experience", "product managers", "production environments", 
            "programming", "proven experience", "python", "python frameworks", "qualifications", 
            "relational database design", "remote", "remote\n\nplacement type", "required", 
            "required qualifications\n programming languages", "restful api design", "restful apis", 
            "robust, scalable, and secure backend services", "role", "salary", "scalable, secure, and performant systems", 
            "seamless data communication", "skills", "soft", "soft skills", "sql", "strong expertise", 
            "strong proficiency", "system design principles", "technical issues", "testing", "that", 
            "the core server-side logic", "the ideal candidate", "the job\nexperience", "the role", "this", 
            "this opportunity", "time", "troubleshoot", "type", "uplers", "uplers' client - moii ai", 
            "web frameworks", "week/160", "what", "work", "you"
        ],
        "experience_requirements": []
    }
    
    # Call the function and print the structured result
    print("Parsing job description keywords...")
    structured_jd = parse_with_gemini(system_prompt, raw_keywords)
    print("\n--- Structured Job Description ---")
    print(json.dumps(structured_jd, indent=2))
    print("--------------------------------\n")


# import google.generativeai as genai
# import os

# # Make sure you have your GOOGLE_API_KEY set as an environment variable
# # or configure it directly:
# genai.configure(api_key="AIzaSyD-7hG4mdgeuhKAXrqfwkD64Ct85bbONuY")

# print("Available models:")
# for m in genai.list_models():
#   # Check if the model supports the 'generateContent' method
#   if 'generateContent' in m.supported_generation_methods:
#     print(f"- {m.name}")